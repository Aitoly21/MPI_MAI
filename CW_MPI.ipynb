{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8tsN1cEql4J",
        "outputId": "d48742c3-6b1f-48c3-e8d8-e4afa2d1e336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp38-cp38-linux_x86_64.whl size=5997345 sha256=fb9fb7ce87c65cf3a7f1945c36469f79468f3aa277e7455a570d05db0eb5310b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/35/48/0b9a7076995eea5ea64a7e4bc3f0f342f453080795276264e7\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./archive.zip"
      ],
      "metadata": {
        "id": "NMX6-_GSrkA7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir weights\n",
        "!touch cw_mpi.py"
      ],
      "metadata": {
        "id": "uHsPI53lu8rA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ссылка на используемый датасет\n",
        "\n",
        "\n",
        "https://www.kaggle.com/datasets/muniryadi/cat-vs-rabbit"
      ],
      "metadata": {
        "id": "2vkRC__g4ydg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun -np 4 --allow-run-as-root --use-hwthread-cpus --oversubscribe python cw_mpi.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y824ij-1u9Id",
        "outputId": "dcdb6cf0-d034-49cb-94c6-30976f64ec64"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@@@@@@@@@@@@@@@@@@@@@@@@ -- TRAIN -- @@@@@@@@@@@@@@@@@@@@@@@@\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
            "  0%|          | 0.00/9.83M [00:00<?, ?B/s]/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
            "100%|██████████| 9.83M/9.83M [00:00<00:00, 50.6MB/s]\n",
            "  0%|          | 0/27 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
            "  0%|          | 0.00/9.83M [00:00<?, ?B/s]/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
            "100%|██████████| 27/27 [00:09<00:00,  2.98it/s]Epoch of train 1: acc -- 0.5296296296296297, loss -- 0.9930715031094022, process -- 1\n",
            "Epoch of train 1: acc -- 0.5296296296296297, loss -- 1.0908385316530864, process -- 2\n",
            "Epoch of train 1: acc -- 0.5230769230769231, loss -- 1.155117548429049, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.73it/s]Epoch of val 1: acc -- 0.55, loss -- 0.8388204872608185, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.64it/s]Epoch of val 1: acc -- 0.5166666666666667, loss -- 0.7314824908971786, process -- 3\n",
            "100%|██████████| 7/7 [00:01<00:00,  3.60it/s]Epoch of val 1: acc -- 0.5697674418604651, loss -- 0.7760751621667729, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:07<00:00,  3.16it/s]Epoch of train 2: acc -- 0.6111111111111112, loss -- 0.8837368885676066, process -- 1\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.32it/s]Epoch of train 2: acc -- 0.6333333333333333, loss -- 0.9030697577529483, process -- 2\n",
            "Epoch of train 2: acc -- 0.6076923076923076, loss -- 0.9615912563525714, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.45it/s]Epoch of val 2: acc -- 0.5333333333333333, loss -- 0.9306333661079407, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.35it/s]Epoch of val 2: acc -- 0.6333333333333333, loss -- 0.6601861119270325, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.42it/s]Epoch of val 2: acc -- 0.5348837209302325, loss -- 0.8649142509283021, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:08<00:00,  3.12it/s]Epoch of train 3: acc -- 0.6814814814814815, loss -- 0.7200047439999051, process -- 1\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.24it/s]Epoch of train 3: acc -- 0.6888888888888889, loss -- 0.7730024192068312, process -- 2\n",
            "Epoch of train 3: acc -- 0.6384615384615384, loss -- 0.9307176516606257, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.84it/s]Epoch of val 3: acc -- 0.5833333333333334, loss -- 0.6925760209560394, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.54it/s]Epoch of val 3: acc -- 0.5166666666666667, loss -- 0.6808715164661407, process -- 3\n",
            "100%|██████████| 7/7 [00:01<00:00,  3.68it/s]Epoch of val 3: acc -- 0.5813953488372093, loss -- 0.702051862727764, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:07<00:00,  3.28it/s]Epoch of train 4: acc -- 0.7296296296296296, loss -- 0.6348001427120633, process -- 1\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.34it/s]Epoch of train 4: acc -- 0.725925925925926, loss -- 0.6136728922526041, process -- 2\n",
            "Epoch of train 4: acc -- 0.6576923076923077, loss -- 0.7859186690587264, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.19it/s]Epoch of val 4: acc -- 0.6, loss -- 0.6621408462524414, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.25it/s]Epoch of val 4: acc -- 0.5333333333333333, loss -- 0.7625015676021576, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.25it/s]Epoch of val 4: acc -- 0.5581395348837209, loss -- 0.6701735091763873, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:07<00:00,  3.39it/s]Epoch of train 5: acc -- 0.7074074074074074, loss -- 0.6239552464750078, process -- 1\n",
            "100%|██████████| 27/27 [00:07<00:00,  3.60it/s]Epoch of train 5: acc -- 0.7481481481481481, loss -- 0.5606357091002994, process -- 2\n",
            "Epoch of train 5: acc -- 0.7538461538461538, loss -- 0.5788331146423633, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.31it/s]Epoch of val 5: acc -- 0.6333333333333333, loss -- 0.6591931879520416, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.52it/s]Epoch of val 5: acc -- 0.6, loss -- 0.6899916529655457, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.42it/s]Epoch of val 5: acc -- 0.5581395348837209, loss -- 0.7583842166634494, process -- 1\n",
            "\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.32it/s]Epoch of train 6: acc -- 0.7555555555555555, loss -- 0.5404804713196225, process -- 1\n",
            "Epoch of train 6: acc -- 0.7769230769230769, loss -- 0.48570263615021336, process -- 3\n",
            "Epoch of train 6: acc -- 0.7962962962962963, loss -- 0.47307704554663765, process -- 2\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.47it/s]Epoch of val 6: acc -- 0.6, loss -- 0.6594712883234024, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.62it/s]Epoch of val 6: acc -- 0.65, loss -- 0.6576263457536697, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.49it/s]Epoch of val 6: acc -- 0.5930232558139535, loss -- 0.7697318528973779, process -- 1\n",
            "\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.30it/s]Epoch of train 7: acc -- 0.7592592592592593, loss -- 0.5894633928934733, process -- 1\n",
            "Epoch of train 7: acc -- 0.823076923076923, loss -- 0.40940363189348805, process -- 3\n",
            "Epoch of train 7: acc -- 0.8111111111111111, loss -- 0.4038507872157627, process -- 2\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.33it/s]Epoch of val 7: acc -- 0.7666666666666667, loss -- 0.5679432153701782, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.37it/s]Epoch of val 7: acc -- 0.6166666666666667, loss -- 0.6408044993877411, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.42it/s]Epoch of val 7: acc -- 0.6046511627906976, loss -- 0.8103864234547282, process -- 1\n",
            "\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.28it/s]Epoch of train 8: acc -- 0.7814814814814814, loss -- 0.5521994762950473, process -- 1\n",
            "Epoch of train 8: acc -- 0.837037037037037, loss -- 0.4144826995001899, process -- 2\n",
            "Epoch of train 8: acc -- 0.8461538461538461, loss -- 0.41282763676001477, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.24it/s]Epoch of val 8: acc -- 0.7666666666666667, loss -- 0.5672476440668106, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.36it/s]Epoch of val 8: acc -- 0.6, loss -- 0.7618054747581482, process -- 3\n",
            "100%|██████████| 7/7 [00:01<00:00,  3.53it/s]Epoch of val 8: acc -- 0.5930232558139535, loss -- 0.7296028982761295, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:08<00:00,  3.22it/s]Epoch of train 9: acc -- 0.8222222222222222, loss -- 0.39060822625954944, process -- 1\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.25it/s]Epoch of train 9: acc -- 0.8703703703703703, loss -- 0.31957985791895127, process -- 2\n",
            "Epoch of train 9: acc -- 0.8461538461538461, loss -- 0.36505771285066235, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  4.06it/s]Epoch of val 9: acc -- 0.7, loss -- 0.6023335456848145, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  4.08it/s]Epoch of val 9: acc -- 0.6, loss -- 0.787280261516571, process -- 3\n",
            "100%|██████████| 7/7 [00:01<00:00,  3.89it/s]Epoch of val 9: acc -- 0.6162790697674418, loss -- 0.7074115775352301, process -- 1\n",
            "\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.37it/s]Epoch of train 10: acc -- 0.8740740740740741, loss -- 0.29478215674559277, process -- 1\n",
            "Epoch of train 10: acc -- 0.8740740740740741, loss -- 0.296362966299057, process -- 2\n",
            "Epoch of train 10: acc -- 0.8692307692307693, loss -- 0.3001325915639217, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.76it/s]Epoch of val 10: acc -- 0.6833333333333333, loss -- 0.649753212928772, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.50it/s]Epoch of val 10: acc -- 0.6, loss -- 0.8581593036651611, process -- 3\n",
            "100%|██████████| 7/7 [00:01<00:00,  3.59it/s]Epoch of val 10: acc -- 0.6976744186046512, loss -- 0.6292950649594151, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:11<00:00,  2.99it/s]Epoch of train 11: acc -- 0.8703703703703703, loss -- 0.314094967312283, process -- 1\n",
            "100%|██████████| 27/27 [00:11<00:00,  2.27it/s]Epoch of train 11: acc -- 0.8666666666666667, loss -- 0.33542241818375057, process -- 2\n",
            "Epoch of train 11: acc -- 0.8576923076923076, loss -- 0.29672748022354567, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.16it/s]Epoch of val 11: acc -- 0.6833333333333333, loss -- 0.5973713099956512, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.20it/s]Epoch of val 11: acc -- 0.5833333333333334, loss -- 0.9358051419258118, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.28it/s]Epoch of val 11: acc -- 0.7906976744186046, loss -- 0.6219283993854079, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:08<00:00,  3.04it/s]Epoch of train 12: acc -- 0.9148148148148149, loss -- 0.22954211715194914, process -- 1\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.19it/s]Epoch of train 12: acc -- 0.8962962962962963, loss -- 0.3087806718217002, process -- 2\n",
            "Epoch of train 12: acc -- 0.9038461538461539, loss -- 0.25284593724287474, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.08it/s]Epoch of val 12: acc -- 0.7333333333333333, loss -- 0.5649423077702522, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.42it/s]Epoch of val 12: acc -- 0.6, loss -- 0.8721935451030731, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.36it/s]Epoch of val 12: acc -- 0.7093023255813954, loss -- 0.699596434138542, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:08<00:00,  2.97it/s]Epoch of train 13: acc -- 0.8888888888888888, loss -- 0.2812790994842847, process -- 1\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.08it/s]Epoch of train 13: acc -- 0.8851851851851852, loss -- 0.2922331690788269, process -- 2\n",
            "Epoch of train 13: acc -- 0.8576923076923076, loss -- 0.4518083924284348, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.42it/s]Epoch of val 13: acc -- 0.7666666666666667, loss -- 0.543889120221138, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.45it/s]Epoch of val 13: acc -- 0.6666666666666666, loss -- 0.6985423564910889, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.42it/s]Epoch of val 13: acc -- 0.7093023255813954, loss -- 0.7922354700953461, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:07<00:00,  3.06it/s]Epoch of train 14: acc -- 0.8925925925925926, loss -- 0.23954191472795275, process -- 1\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.34it/s]Epoch of train 14: acc -- 0.9037037037037037, loss -- 0.2761746421456337, process -- 2\n",
            "Epoch of train 14: acc -- 0.8769230769230769, loss -- 0.2690209557230656, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.36it/s]Epoch of val 14: acc -- 0.7833333333333333, loss -- 0.5308089032769203, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.39it/s]Epoch of val 14: acc -- 0.6333333333333333, loss -- 0.7469296157360077, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.49it/s]Epoch of val 14: acc -- 0.7209302325581395, loss -- 0.8520569066668666, process -- 1\n",
            "\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.29it/s]Epoch of train 15: acc -- 0.9148148148148149, loss -- 0.21749786370330387, process -- 1\n",
            "Epoch of train 15: acc -- 0.8851851851851852, loss -- 0.24062265207370123, process -- 2\n",
            "Epoch of train 15: acc -- 0.8653846153846154, loss -- 0.3217621434193391, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  4.09it/s]Epoch of val 15: acc -- 0.75, loss -- 0.507525235414505, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  4.30it/s]Epoch of val 15: acc -- 0.6666666666666666, loss -- 0.824978232383728, process -- 3\n",
            "100%|██████████| 7/7 [00:01<00:00,  3.83it/s]Epoch of val 15: acc -- 0.7325581395348837, loss -- 0.8324250592741855, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:08<00:00,  2.76it/s]Epoch of train 16: acc -- 0.9074074074074074, loss -- 0.24146396418412527, process -- 1\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.03it/s]Epoch of train 16: acc -- 0.9, loss -- 0.21001886990335253, process -- 2\n",
            "Epoch of train 16: acc -- 0.8769230769230769, loss -- 0.3432220747837654, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.63it/s]Epoch of val 16: acc -- 0.8, loss -- 0.49651816487312317, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.51it/s]Epoch of val 16: acc -- 0.6666666666666666, loss -- 0.8113595545291901, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.48it/s]Epoch of val 16: acc -- 0.7674418604651163, loss -- 0.9107244111770807, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:08<00:00,  3.15it/s]Epoch of train 17: acc -- 0.8962962962962963, loss -- 0.2560778765214814, process -- 1\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.26it/s]Epoch of train 17: acc -- 0.9222222222222223, loss -- 0.2062960291902224, process -- 2\n",
            "Epoch of train 17: acc -- 0.9038461538461539, loss -- 0.20629892612879092, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.54it/s]Epoch of val 17: acc -- 0.8, loss -- 0.5003825575113297, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.49it/s]Epoch of val 17: acc -- 0.6833333333333333, loss -- 0.81708624958992, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.48it/s]Epoch of val 17: acc -- 0.7093023255813954, loss -- 0.7874023720275524, process -- 1\n",
            "\n",
            " 96%|█████████▋| 26/27 [00:08<00:00,  3.07it/s]Epoch of train 18: acc -- 0.9, loss -- 0.21915219061904484, process -- 1\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.22it/s]Epoch of train 18: acc -- 0.8962962962962963, loss -- 0.26310618428720367, process -- 2\n",
            "Epoch of train 18: acc -- 0.9076923076923077, loss -- 0.2633046782933749, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.96it/s]Epoch of val 18: acc -- 0.85, loss -- 0.5451540052890778, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.95it/s]Epoch of val 18: acc -- 0.75, loss -- 0.7777298986911774, process -- 3\n",
            "100%|██████████| 7/7 [00:01<00:00,  3.96it/s]Epoch of val 18: acc -- 0.7558139534883721, loss -- 0.8042757178461829, process -- 1\n",
            "\n",
            "100%|██████████| 27/27 [00:07<00:00,  3.39it/s]Epoch of train 19: acc -- 0.9296296296296296, loss -- 0.1741403310249249, process -- 1\n",
            "Epoch of train 19: acc -- 0.9115384615384615, loss -- 0.2446347072433967, process -- 3\n",
            "Epoch of train 19: acc -- 0.9333333333333333, loss -- 0.18137568028436768, process -- 2\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  3.28it/s]Epoch of val 19: acc -- 0.7833333333333333, loss -- 0.6851137727499008, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  3.24it/s]Epoch of val 19: acc -- 0.7, loss -- 0.7488230168819427, process -- 3\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.28it/s]Epoch of val 19: acc -- 0.7441860465116279, loss -- 0.7728060400763224, process -- 1\n",
            "\n",
            "100%|██████████| 27/27 [00:08<00:00,  3.21it/s]Epoch of train 20: acc -- 0.9407407407407408, loss -- 0.16530335280630323, process -- 1\n",
            "Epoch of train 20: acc -- 0.9296296296296296, loss -- 0.1877139194144143, process -- 2\n",
            "Epoch of train 20: acc -- 0.9153846153846154, loss -- 0.24583393335342407, process -- 3\n",
            "\n",
            " 71%|███████▏  | 5/7 [00:01<00:00,  4.89it/s]Epoch of val 20: acc -- 0.75, loss -- 0.700852245092392, process -- 2\n",
            " 86%|████████▌ | 6/7 [00:01<00:00,  4.38it/s]Epoch of val 20: acc -- 0.6833333333333333, loss -- 0.7746285200119019, process -- 3\n",
            "100%|██████████| 7/7 [00:01<00:00,  4.28it/s]Epoch of val 20: acc -- 0.7325581395348837, loss -- 0.9415649757828823, process -- 1\n",
            "@@@@@@@@@@@@@@@@@@@@@@@@ -- TEST -- @@@@@@@@@@@@@@@@@@@@@@@@\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]Test: acc -- 0.7333333333333333, loss -- 0.5240681767463684, process -- 2\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.30it/s]Test: acc -- 0.8666666666666667, loss -- 0.32288509607315063, process -- 3\n",
            "\n",
            "Test process 0: acc -- 0.8666666666666667\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.29it/s]Test: acc -- 0.7333333333333333, loss -- 0.5642793774604797, process -- 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat cw_mpi.py"
      ],
      "metadata": {
        "id": "-fh0PuHWw3N-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c56462-8fb7-4e26-f4c2-8102d21aca02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import torch\r\n",
            "import torchvision\r\n",
            "from torch.utils.data import Dataset\r\n",
            "from torchvision import datasets, transforms, models\r\n",
            "from torchvision.datasets.vision import data\r\n",
            "from torchvision.transforms import ToTensor\r\n",
            "import os\r\n",
            "import pandas as pd\r\n",
            "from PIL import Image\r\n",
            "import cv2\r\n",
            "from mpi4py import MPI\r\n",
            "import torch.optim as optim\r\n",
            "import torch.nn as nn\r\n",
            "from tqdm import tqdm\r\n",
            "\r\n",
            "def train(model, criterion, optimizer, dataloader, sizes, my_rank, epochs=10):\r\n",
            "    for epoch in range(epochs):\r\n",
            "        model.train()\r\n",
            "        epoch_loss = 0.0\r\n",
            "        score = 0\r\n",
            "        if my_rank == 0:\r\n",
            "            iteration = 0\r\n",
            "            for image, label in tqdm(dataloader['train']):\r\n",
            "                comm.send(image, dest=iteration % (p - 1) + 1, tag=0)\r\n",
            "                comm.send(label, dest=iteration % (p - 1) + 1, tag=1)\r\n",
            "                iteration += 1\r\n",
            "        if my_rank != 0:\r\n",
            "            size = 0\r\n",
            "            for i in range(len(dataloader['train'])):\r\n",
            "                if i % (p - 1) + 1 == my_rank:\r\n",
            "                    image = comm.recv(source=0, tag=0)\r\n",
            "                    label = comm.recv(source=0, tag=1)\r\n",
            "                    size += image.size(0)\r\n",
            "                    optimizer.zero_grad()\r\n",
            "                    out = model(image)\r\n",
            "                    _, preds = torch.max(out, 1)\r\n",
            "                    loss = criterion(out, label)\r\n",
            "                    loss.backward()\r\n",
            "                    optimizer.step()\r\n",
            "                    epoch_loss += loss.item() * image.size(0)\r\n",
            "                    score += torch.sum(preds == label.data)\r\n",
            "            epoch_acc = score.double() / size \r\n",
            "            epoch_loss = epoch_loss / size\r\n",
            "            print(f\"Epoch of train {epoch + 1}: acc -- {epoch_acc.item()}, loss -- {epoch_loss}, process -- {my_rank}\")\r\n",
            "        MPI.Comm.Barrier(MPI.COMM_WORLD)\r\n",
            "        score = 0\r\n",
            "        epoch_loss = 0.0\r\n",
            "        model.eval()\r\n",
            "        with torch.no_grad():\r\n",
            "            if my_rank == 0:\r\n",
            "                iteration = 0\r\n",
            "                for image, label in tqdm(dataloader['val']):\r\n",
            "                    comm.send(image, dest=iteration % (p - 1) + 1, tag=0)\r\n",
            "                    comm.send(label, dest=iteration % (p - 1) + 1, tag=1)\r\n",
            "                    iteration += 1\r\n",
            "            if my_rank != 0:\r\n",
            "                size = 0\r\n",
            "                for i in range(len(dataloader['val'])):\r\n",
            "                    if i % (p - 1) + 1 == my_rank:\r\n",
            "                        image = comm.recv(source=0, tag=0)\r\n",
            "                        label = comm.recv(source=0, tag=1)\r\n",
            "                        size += image.size(0)\r\n",
            "                        out = model(image)\r\n",
            "                        _, preds = torch.max(out, 1)\r\n",
            "                        loss = criterion(out, label)\r\n",
            "                        epoch_loss += loss.item() * image.size(0)\r\n",
            "                        score += torch.sum(preds == label.data)\r\n",
            "                epoch_acc = score.double() / size\r\n",
            "                epoch_loss = epoch_loss / size\r\n",
            "                print(f\"Epoch of val {epoch + 1}: acc -- {epoch_acc.item()}, loss -- {epoch_loss}, process -- {my_rank}\")\r\n",
            "            MPI.Comm.Barrier(MPI.COMM_WORLD)\r\n",
            "    return model\r\n",
            "\r\n",
            "def test(model, criterion, dataloader_test, dataset_sizes_test):\r\n",
            "    score = 0\r\n",
            "    epoch_loss = 0.0\r\n",
            "    model.eval()\r\n",
            "    result = 0\r\n",
            "    with torch.no_grad():\r\n",
            "        if my_rank != 0:\r\n",
            "            for image, label in tqdm(dataloader_test):\r\n",
            "                out = model(image)\r\n",
            "                comm.send(out, dest=0, tag=0)\r\n",
            "                _, preds = torch.max(out, 1)\r\n",
            "                loss = criterion(out, label)\r\n",
            "                epoch_loss += loss.item() * image.size(0)\r\n",
            "                score += torch.sum(preds == label.data)\r\n",
            "            epoch_acc = score.double() / dataset_sizes_test\r\n",
            "            epoch_loss = epoch_loss / dataset_sizes_test\r\n",
            "            print(f\"Test: acc -- {epoch_acc.item()}, loss -- {epoch_loss}, process -- {my_rank}\")\r\n",
            "        if my_rank == 0:\r\n",
            "            result = 0\r\n",
            "            for _, label in dataloader_test:\r\n",
            "                result_all_models = torch.zeros(label.size(0), 2)\r\n",
            "                for procid in range(1, p):\r\n",
            "                    out = comm.recv(source=procid, tag=0)\r\n",
            "                    result_all_models += out\r\n",
            "                result_all_models /= p - 1\r\n",
            "                _, preds = torch.max(result_all_models, 1)\r\n",
            "                result += torch.sum(preds == label.data)\r\n",
            "            result = result.double() / dataset_sizes_test\r\n",
            "            print(f\"Test process {my_rank}: acc -- {result.item()}\")\r\n",
            "\r\n",
            "class Dataset_Creature(Dataset):\r\n",
            "    def __init__(self, root_dir, transforms=None):\r\n",
            "        self.root_dir = root_dir\r\n",
            "        self.data_frame=self.pars_data()\r\n",
            "        self.transforms=transforms\r\n",
            "\r\n",
            "    def pars_data(self):\r\n",
            "        data_frame = list()\r\n",
            "        if self.root_dir == './train-cat-rabbit' or self.root_dir == './val-cat-rabbit':\r\n",
            "            cat = self.root_dir + '/cat'\r\n",
            "            list_dir = os.listdir(cat)\r\n",
            "            for i in range(int(len(list_dir) / 2)):\r\n",
            "                data_frame.append([f'{cat}/{list_dir[i]}', 0])\r\n",
            "            rabbit = self.root_dir + '/rabbit'\r\n",
            "            list_dir = os.listdir(rabbit)\r\n",
            "            for i in range(int(len(list_dir) / 2)):\r\n",
            "                data_frame.append([f'{rabbit}/{list_dir[i]}', 1])\r\n",
            "            return pd.DataFrame(data_frame, columns=[0, 1])\r\n",
            "        else:\r\n",
            "            cat = self.root_dir + '/cat'\r\n",
            "            list_dir = os.listdir(cat)\r\n",
            "            for i in range(len(list_dir)):\r\n",
            "                data_frame.append([f'{cat}/{list_dir[i]}', 0])\r\n",
            "            rabbit = self.root_dir + '/rabbit'\r\n",
            "            list_dir = os.listdir(rabbit)\r\n",
            "            for i in range(len(list_dir)):\r\n",
            "                data_frame.append([f'{rabbit}/{list_dir[i]}', 1])\r\n",
            "            return pd.DataFrame(data_frame, columns=[0, 1])\r\n",
            "\r\n",
            "    def __len__(self):\r\n",
            "        return len(self.data_frame)\r\n",
            "\r\n",
            "    def __getitem__(self, idx):\r\n",
            "        path = self.data_frame.iloc[idx, 0]\r\n",
            "        image = Image.open(path).convert('RGB')\r\n",
            "        label = self.data_frame.iloc[idx, 1]\r\n",
            "        if self.transforms:\r\n",
            "            image = self.transforms(image)\r\n",
            "        return image, label\r\n",
            "\r\n",
            "def Create_Dataloader(condition, datas, transform=None, shuffles=None):\r\n",
            "    if condition == True:\r\n",
            "        d_dataloaders = {}\r\n",
            "        d_sizes = {}\r\n",
            "        for data_type, shuffle, data in zip(['train', 'val'], shuffles, datas):\r\n",
            "            dataset = Dataset_Creature(root_dir=data, transforms=transform)\r\n",
            "            d_dataloaders[data_type] = torch.utils.data.DataLoader(dataset, batch_size=30, shuffle=shuffle)\r\n",
            "            d_sizes[data_type] = len(dataset)\r\n",
            "        return d_dataloaders, d_sizes\r\n",
            "    else:\r\n",
            "        dataset = Dataset_Creature(root_dir=datas, transforms=transform)\r\n",
            "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=30, shuffle=False)\r\n",
            "        dataset_sizes = len(dataset)\r\n",
            "        return dataloader, dataset_sizes\r\n",
            "\r\n",
            "def Model_Create():\r\n",
            "    criterion = nn.CrossEntropyLoss()\r\n",
            "    model_ft = models.mobilenet_v3_small(pretrained=True)\r\n",
            "    model_ft.classifier[3] = torch.nn.Linear(in_features=model_ft.classifier[3].in_features, out_features=2)\r\n",
            "    optimizer_ft = optim.AdamW(model_ft.parameters(), lr=0.001)\r\n",
            "    return model_ft, criterion, optimizer_ft\r\n",
            "\r\n",
            "if __name__ == \"__main__\":\r\n",
            "    transform = transforms.Compose([\r\n",
            "        transforms.Resize((32, 32)), \r\n",
            "        transforms.ToTensor(),\r\n",
            "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
            "        ])\r\n",
            "    dataloader, sizes = Create_Dataloader(condition=True, datas=['./train-cat-rabbit', './val-cat-rabbit'], transform=transform, shuffles=[True, False])\r\n",
            "    comm = MPI.COMM_WORLD\r\n",
            "    my_rank = comm.Get_rank()\r\n",
            "    p = comm.Get_size()\r\n",
            "    if my_rank == 0:\r\n",
            "        print(\"@@@@@@@@@@@@@@@@@@@@@@@@ -- TRAIN -- @@@@@@@@@@@@@@@@@@@@@@@@\")\r\n",
            "    model, criterion, optimizer = Model_Create()\r\n",
            "    model = train(model, criterion, optimizer, dataloader, sizes, my_rank, epochs=20)\r\n",
            "    MPI.Comm.Barrier(MPI.COMM_WORLD)\r\n",
            "    if my_rank == 0:\r\n",
            "        print(\"@@@@@@@@@@@@@@@@@@@@@@@@ -- TEST -- @@@@@@@@@@@@@@@@@@@@@@@@\")\r\n",
            "    dataloader, sizes = Create_Dataloader(condition=False, datas='./test-images', transform=transform)\r\n",
            "    test(model, criterion, dataloader, sizes)\r\n",
            "    MPI.Finalize"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M4Wlv8Yn5N0m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}